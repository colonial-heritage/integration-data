name: Update Search Graph with data from dataset 'Collection Archives' in the Knowledge Graph

# Every hour
on:
  schedule:
    - cron: "0 * * * *"

# Run a single workflow at a time
concurrency:
  group: search-graph

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout data repository
        uses: actions/checkout@v4
        with:
          path: ./data
          # No 'sparse-checkout': that's actually slower than checking out the full repo
      - name: Checkout code repository
        uses: actions/checkout@v4
        with:
          path: ./code
          repository: colonial-heritage/integration-layer
      - name: Install Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
      - name: Install app
        run: |
          cd ./code
          npm install --no-progress
          npx turbo run build --filter=@colonial-collections/graph-create
      - name: Create graph
        run: |
          cd ./data
          mkdir -p "$RUNNER_TEMP"
          test -f ./nmvw-collection-archives/data/data.tar.zst && tar --zstd -xf ./nmvw-collection-archives/data/data.tar.zst -C "$RUNNER_TEMP"
          ../code/apps/graph-create/dist/cli.js create \
            --resource-dir ./nmvw-collection-archives/resources \
            --data-file "$RUNNER_TEMP/data.sqlite" \
            --check-endpoint-url "${{ vars.SPARQL_ENDPOINT_URL_KG }}" \
            --check-if-run-must-continue-query-file ./nmvw-collection-archives/queries/check.rq \
            --iterate-endpoint-url "${{ vars.SPARQL_ENDPOINT_URL_KG }}" \
            --iterate-query-file ./nmvw-collection-archives/queries/iterate.rq \
            --generate-endpoint-url "${{ vars.SPARQL_ENDPOINT_URL_KG }}" \
            --generate-query-file ./nmvw-collection-archives/queries/generate.rq \
            --triplydb-instance-url "${{ vars.TRIPLYDB_INSTANCE_URL }}" \
            --triplydb-api-token "${{ secrets.TRIPLYDB_API_TOKEN }}" \
            --triplydb-account "${{ vars.TRIPLYDB_ACCOUNT }}" \
            --triplydb-dataset "${{ vars.TRIPLYDB_DATASET_SG }}" \
            --triplydb-service-name "search" \
            --triplydb-service-type "elasticsearch" \
            --graph-name "https://data.colonialcollections.nl/nmvw-collection-archives" \
            --temp-dir "$RUNNER_TEMP"
      - name: Save changes
        run: |
          cd ./data
          mkdir -p ./nmvw-collection-archives/data
          test -f "$RUNNER_TEMP/data.sqlite" && tar --zstd -cf ./nmvw-collection-archives/data/data.tar.zst -C "$RUNNER_TEMP" data.sqlite
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git commit --quiet -a -m "Save changes" || true
          git push --force -u origin
